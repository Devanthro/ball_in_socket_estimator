{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482e0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import os\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23306a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346086 values\n"
     ]
    }
   ],
   "source": [
    "# body_part = \"head\"\n",
    "# file_names = ['./data/training_data/head_data_1.log',\n",
    "#              './data/training_data/head_data_2.log',\n",
    "#              './data/training_data/head_data_3.log',\n",
    "#              './data/training_data/head_data_4.log',\n",
    "#              './data/training_data/head_data_5.log',\n",
    "#              './data/training_data/head_data_6.log']\n",
    "\n",
    "body_part = \"shoulder_right\"\n",
    "file_names = [\n",
    "             './data/training_data/shoulder_right_data_6.log',\n",
    "             './data/training_data/shoulder_right_data_7.log',\n",
    "             './data/training_data/shoulder_right_data_8.log',\n",
    "             './data/training_data/shoulder_right_data_9.log',\n",
    "             './data/training_data/shoulder_right_data_14.log',\n",
    "             './data/training_data/shoulder_right_data_15.log',\n",
    "             './data/training_data/shoulder_right_data_16.log',\n",
    "             './data/training_data/shoulder_right_data_17.log']\n",
    "\n",
    "# body_part = \"shoulder_left\"\n",
    "# file_names = ['./data/training_data/shoulder_left_data_1.log',\n",
    "#               './data/training_data/shoulder_left_data_2.log',\n",
    "#               './data/training_data/shoulder_left_data_3.log']\n",
    "\n",
    "dataset = [pd.read_csv(f, delim_whitespace=True, header=0) for f in file_names]\n",
    "dataset = [data[(np.abs(stats.zscore(data[[\"roll\", \"pitch\", \"yaw\"]])) < 2.75).all(axis=1)] for data in dataset]\n",
    "dataset_len = [len(data) for data in dataset]\n",
    "dataset = pd.concat(dataset)\n",
    "\n",
    "print('%d values'%(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a0174b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8241, 67523, 37184, 57790, 12928, 12195, 7290, 142935]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026edec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346084 values after filtering outliers\n",
      "max euler 1.411555809406252\n",
      "min euler -2.271037073466141\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.values[1:len(dataset)-1,0:]\n",
    "# np.random.shuffle(dataset)\n",
    "\n",
    "dataset = dataset[abs(dataset[:,12])!=0.0,:]\n",
    "dataset = dataset[abs(dataset[:,13])!=0.0,:]\n",
    "dataset = dataset[abs(dataset[:,14])!=0.0,:]\n",
    "print('%d values after filtering outliers'%(len(dataset)))\n",
    "\n",
    "euler_set = dataset[:, 12:15]\n",
    "print('max euler ' + str(np.amax(euler_set)))\n",
    "print('min euler ' + str(np.amin(euler_set)))\n",
    "sensors_set = dataset[:, :12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a18c2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_cos_set = np.hstack([np.sin(euler_set), np.cos(euler_set)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29089bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors_scaler = MinMaxScaler(feature_range=(-1., 1.))\n",
    "sensors_set = sensors_scaler.fit_transform(sensors_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1825d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = 0.8\n",
    "split_idx = int(len(sensors_set)*data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c84d04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8221\n",
      "75724\n",
      "112888\n",
      "170658\n",
      "183566\n",
      "195741\n",
      "203011\n",
      "345926\n"
     ]
    }
   ],
   "source": [
    "look_back = 10\n",
    "\n",
    "data_in = []\n",
    "data_out = []\n",
    "\n",
    "start_idx = 0\n",
    "for l in dataset_len:\n",
    "    # Ignore the last batch\n",
    "    for i in range(start_idx, start_idx+l-look_back*2):\n",
    "        data_in.append(sensors_set[i:i+look_back])\n",
    "        data_out.append(sin_cos_set[i+1:i+look_back+1])\n",
    "    print(len(data_in))\n",
    "    start_idx += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1531645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = 0.8\n",
    "data_idx = np.arange(len(data_in))\n",
    "np.random.shuffle(data_idx)\n",
    "split_idx = int(len(data_in)*data_split)\n",
    "\n",
    "train_in = np.array(data_in)[data_idx[:split_idx]]\n",
    "train_out = np.array(data_out)[data_idx[:split_idx]]\n",
    "test_in = np.array(data_in)[data_idx[split_idx:]]\n",
    "test_out = np.array(data_out)[data_idx[split_idx:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd53c828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276740, 10, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_in.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182f02f",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81e0317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/roboy/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from nn_model import NeuralNetworkModel, LSTMNeuralNetworkModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d12ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roboy/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/home/roboy/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0000: Traing loss 0.59783, Valid loss 0.18706\n",
      "#0010: Traing loss 0.01021, Valid loss 0.00961\n",
      "#0020: Traing loss 0.00450, Valid loss 0.00445\n",
      "#0030: Traing loss 0.00286, Valid loss 0.00283\n",
      "#0040: Traing loss 0.00222, Valid loss 0.00229\n",
      "#0050: Traing loss 0.00186, Valid loss 0.00190\n",
      "#0060: Traing loss 0.00169, Valid loss 0.00179\n",
      "#0070: Traing loss 0.00153, Valid loss 0.00153\n",
      "#0080: Traing loss 0.00143, Valid loss 0.00146\n",
      "#0090: Traing loss 0.00133, Valid loss 0.00144\n",
      "#0100: Traing loss 0.00128, Valid loss 0.00127\n",
      "#0110: Traing loss 0.00121, Valid loss 0.00122\n",
      "#0120: Traing loss 0.00117, Valid loss 0.00119\n",
      "#0130: Traing loss 0.00110, Valid loss 0.00110\n",
      "#0140: Traing loss 0.00109, Valid loss 0.00107\n",
      "#0150: Traing loss 0.00103, Valid loss 0.00105\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ebce53645027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMNeuralNetworkModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# model = NeuralNetworkModel(name=body_part, hidden_size=100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m model.fit(x=train_in, y=train_out, x_val=test_in, y_val=test_out, save_path=model_name, \n\u001b[0m\u001b[1;32m     12\u001b[0m          iteration=500, patience=100, batch_size=1000)\n",
      "\u001b[0;32m~/roboy3/src/ball_in_socket_estimator/python/nn_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, x_val, y_val, save_path, iteration, patience, batch_size)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 }\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mtraining_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_train_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/roboy/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = './output/'+body_part+'_lstm'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "model_name = model_path+'/best_model'\n",
    "joblib.dump(sensors_scaler, model_path+'/scaler.pkl') \n",
    "\n",
    "model = LSTMNeuralNetworkModel(name=body_part, hidden_size=100, look_back=look_back)\n",
    "# model = NeuralNetworkModel(name=body_part, hidden_size=100)\n",
    "model.fit(x=train_in, y=train_out, x_val=test_in, y_val=test_out, save_path=model_name, \n",
    "         iteration=500, patience=100, batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
